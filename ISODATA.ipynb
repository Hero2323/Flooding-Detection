{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISODATA:\n",
    "    def __init__(self, image_path, starting_number_of_clusters=20, desired_number_of_clusters=10,\n",
    "                 maximum_number_of_clusters=50, minimum_number_of_pixels_per_cluster=50,\n",
    "                 exclusion_distance=200, closeness_criterion=30, elongation_criterion=16,\n",
    "                 maximum_number_of_iterations=35, maximum_number_of_clusters_that_can_be_merged_at_one_time=2,\n",
    "                 relative_decline_in_inter_cluster_center_distance=1,\n",
    "                 absolute_value_of_inter_cluster_center_distance=5):\n",
    "        # Read the image into a NumPy array\n",
    "        image = imageio.imread(image_path)\n",
    "\n",
    "        # Convert the image to a 2D array of pixels\n",
    "        self.data = image.reshape((-1, 3))\n",
    "        \n",
    "        # Initialize the array to store the cluster assignments\n",
    "        self.closest = np.zeros(self.data.shape[0], dtype=int)\n",
    "        \n",
    "        # Initialize the centroids attribute\n",
    "        self.centroids = None\n",
    "        \n",
    "        # Store the parameters as attributes\n",
    "        self.starting_number_of_clusters = starting_number_of_clusters\n",
    "        self.desired_number_of_clusters = desired_number_of_clusters\n",
    "        self.maximum_number_of_clusters = maximum_number_of_clusters\n",
    "        self.minimum_number_of_pixels_per_cluster = minimum_number_of_pixels_per_cluster\n",
    "        self.exclusion_distance = exclusion_distance\n",
    "        self.closeness_criterion = closeness_criterion\n",
    "        self.elongation_criterion = elongation_criterion\n",
    "        self.maximum_number_of_iterations = maximum_number_of_iterations\n",
    "        self.maximum_number_of_clusters_that_can_be_merged_at_one_time = maximum_number_of_clusters_that_can_be_merged_at_one_time\n",
    "        self.relative_decline_in_inter_cluster_center_distance = relative_decline_in_inter_cluster_center_distance\n",
    "        self.absolute_value_of_inter_cluster_center_distance = absolute_value_of_inter_cluster_center_distance\n",
    "\n",
    "    def initialize_centroids(self):\n",
    "        \"\"\"returns k centroids from the initial points\"\"\"\n",
    "        centroids = self.data.copy()\n",
    "        np.random.shuffle(centroids)\n",
    "        self.centroids = centroids[:self.starting_number_of_clusters]\n",
    "\n",
    "    def closest_centroid(self):\n",
    "        \"\"\"returns an array containing the index to the nearest centroid for each point\"\"\"\n",
    "        distances = np.sqrt(((self.data - self.centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        self.closest = np.argmin(distances, axis=0)\n",
    "\n",
    "    def move_centroids(self):\n",
    "        \"\"\"returns the new centroids assigned from the points closest to them\"\"\"\n",
    "        self.centroids = np.array([self.data[self.closest==k].mean(axis=0) for k in range(self.centroids.shape[0])])\n",
    "    \n",
    "    def split_clusters(self):\n",
    "        \"\"\"Split clusters if the standard deviation along any dimension is greater than the user-defined split threshold\"\"\"\n",
    "        new_centroids = []\n",
    "        for k in range(self.centroids.shape[0]):\n",
    "            cluster_data = self.data[self.closest==k]\n",
    "            if cluster_data.shape[0] > 0:\n",
    "                std_devs = np.std(cluster_data, axis=0)\n",
    "                if np.any(std_devs > self.elongation_criterion):\n",
    "                    new_centroids.append(self.centroids[k] - std_devs)\n",
    "                    new_centroids.append(self.centroids[k] + std_devs)\n",
    "                else:\n",
    "                    new_centroids.append(self.centroids[k])\n",
    "        self.centroids = np.array(new_centroids)\n",
    "\n",
    "    def merge_clusters(self):\n",
    "        \"\"\"Merge clusters if their separation distance in multispectral feature space is less than a user-specified value\"\"\"\n",
    "        new_centroids = self.centroids.copy()\n",
    "        num_merged = 0\n",
    "        for i in range(self.centroids.shape[0]):\n",
    "            for j in range(i+1, self.centroids.shape[0]):\n",
    "                dist = np.sqrt(np.sum((self.centroids[i] - self.centroids[j])**2))\n",
    "                if dist < self.closeness_criterion:\n",
    "                    new_centroid = (self.centroids[i] + self.centroids[j]) / 2\n",
    "                    new_centroids[i] = new_centroid\n",
    "                    new_centroids = np.delete(new_centroids, j, axis=0)\n",
    "                    num_merged += 1\n",
    "                    if num_merged >= self.maximum_number_of_clusters_that_can_be_merged_at_one_time:\n",
    "                        break\n",
    "            if num_merged >= self.maximum_number_of_clusters_that_can_be_merged_at_one_time:\n",
    "                break\n",
    "        self.centroids = new_centroids\n",
    "\n",
    "    def delete_clusters(self):\n",
    "        \"\"\"Delete clusters if they have fewer members than a user-specified minimum\"\"\"\n",
    "        new_centroids = []\n",
    "        for k in range(self.centroids.shape[0]):\n",
    "            cluster_size = np.sum(self.closest == k)\n",
    "            if cluster_size >= self.minimum_number_of_pixels_per_cluster:\n",
    "                new_centroids.append(self.centroids[k])\n",
    "        self.centroids = np.array(new_centroids)\n",
    "\n",
    "def run(self):\n",
    "    \"\"\"Run the ISODATA algorithm\"\"\"\n",
    "    # Initialize the centroids\n",
    "    self.initialize_centroids()\n",
    "    \n",
    "    for i in range(self.maximum_number_of_iterations):\n",
    "        # Assign each data point to the closest centroid\n",
    "        self.closest_centroid()\n",
    "        \n",
    "        # Move the centroids to the mean of the points assigned to them\n",
    "        old_centroids = self.centroids.copy()\n",
    "        self.move_centroids()\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.allclose(old_centroids, self.centroids):\n",
    "            print(f\"Converged after {i+1} iterations\")\n",
    "            break\n",
    "        \n",
    "        # Split clusters if necessary\n",
    "        self.split_clusters()\n",
    "        \n",
    "        # Merge clusters if necessary\n",
    "        self.merge_clusters()\n",
    "        \n",
    "        # Delete clusters if necessary\n",
    "        self.delete_clusters()\n",
    "        \n",
    "        print(f\"Iteration {i+1}: {self.centroids.shape[0]} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eefc6a63c6d719296cee5685f23fefb92aa63e2e9fdaf52ddbdc4ce266c7bb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
