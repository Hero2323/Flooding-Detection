{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data.dataset import Dataset \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms,models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.metrics import f1_score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), # data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "     transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "     transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"Data/train/\"\n",
    "test_dir = \"Data/test/\"\n",
    "val_dir= \"Data/val/\"\n",
    "train_flooded_dir = \"Data/train/flooded/\"\n",
    "train_non_flooded_dir = \"Data/train/non-flooded/\"\n",
    "val_flooded_dir = \"Data/val/flooded/\"\n",
    "val_non_flooded_dir = \"Data/val/non-flooded/\"\n",
    "test_flooded_dir = \"Data/test/flooded/\"\n",
    "test_non_flooded_dir = \"Data/test/non-flooded/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(train_dir, transforms_train)\n",
    "test_dataset = ImageFolder(test_dir, transforms_test)\n",
    "val_dataset = ImageFolder(val_dir, transforms_val)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=12, shuffle=True, num_workers=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 644\n",
      "Test dataset size: 140\n",
      "Val dataset size: 138\n",
      "Class names: ['flooded', 'non-flooded']\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size:', len(train_dataset))\n",
    "print('Test dataset size:', len(test_dataset))\n",
    "print('Val dataset size:', len(val_dataset))\n",
    "class_names = train_dataset.classes\n",
    "print('Class names:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rorod\\miniforge3\\envs\\new_python_nlp_2\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\Users\\rorod\\miniforge3\\envs\\new_python_nlp_2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)   #load resnet18 model\n",
    "num_features = model.fc.in_features     #extract fc layers features\n",
    "model.fc = nn.Linear(num_features, 2) #(num_of_class == 2)\n",
    "model = model.to(device) \n",
    "criterion = nn.CrossEntropyLoss()  #(set loss function)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 running\n",
      "[Train #0] Loss: 0.0687 Acc: 97.2050% Time: 59.8535s\n",
      "F1-Score 0.9719626168224299\n",
      "F1-Score 0.9855072463768115\n",
      "[Val #0] Loss: 0.0220 Acc: 100.0000% Time: 69.2340s\n",
      "Epoch 1 running\n",
      "[Train #1] Loss: 0.0370 Acc: 98.6025% Time: 128.8917s\n",
      "F1-Score 0.9860465116279069\n",
      "F1-Score 1.0\n",
      "[Val #1] Loss: 0.0174 Acc: 101.4493% Time: 135.9583s\n",
      "Epoch 2 running\n",
      "[Train #2] Loss: 0.0582 Acc: 97.9814% Time: 196.1721s\n",
      "F1-Score 0.9799072642967542\n",
      "F1-Score 0.9928057553956835\n",
      "[Val #2] Loss: 0.0252 Acc: 100.7246% Time: 202.9996s\n",
      "Epoch 3 running\n",
      "[Train #3] Loss: 0.0354 Acc: 99.0683% Time: 262.6492s\n",
      "F1-Score 0.9906832298136646\n",
      "F1-Score 0.9928057553956835\n",
      "[Val #3] Loss: 0.0212 Acc: 100.7246% Time: 269.4287s\n",
      "Epoch 4 running\n",
      "[Train #4] Loss: 0.0530 Acc: 98.1366% Time: 329.5719s\n",
      "F1-Score 0.9814241486068113\n",
      "F1-Score 0.9929078014184397\n",
      "[Val #4] Loss: 0.0348 Acc: 100.7246% Time: 336.3504s\n",
      "Epoch 5 running\n",
      "[Train #5] Loss: 0.0692 Acc: 97.6708% Time: 395.5775s\n",
      "F1-Score 0.9765990639625585\n",
      "F1-Score 0.9787234042553192\n",
      "[Val #5] Loss: 0.0586 Acc: 99.2754% Time: 402.2890s\n",
      "Epoch 6 running\n",
      "[Train #6] Loss: 0.0739 Acc: 97.2050% Time: 461.2629s\n",
      "F1-Score 0.9722222222222223\n",
      "F1-Score 0.9784172661870504\n",
      "[Val #6] Loss: 0.0767 Acc: 99.2754% Time: 467.8385s\n",
      "Epoch 7 running\n",
      "[Train #7] Loss: 0.0571 Acc: 98.4472% Time: 528.5724s\n",
      "F1-Score 0.9844236760124611\n",
      "F1-Score 0.9929078014184397\n",
      "[Val #7] Loss: 0.0285 Acc: 100.7246% Time: 535.2069s\n",
      "Epoch 8 running\n",
      "[Train #8] Loss: 0.0839 Acc: 96.7391% Time: 595.8051s\n",
      "F1-Score 0.9676425269645609\n",
      "F1-Score 1.0\n",
      "[Val #8] Loss: 0.0203 Acc: 101.4493% Time: 602.8667s\n",
      "Epoch 9 running\n",
      "[Train #9] Loss: 0.0629 Acc: 97.5155% Time: 663.0200s\n",
      "F1-Score 0.9752321981424149\n",
      "F1-Score 0.9784172661870504\n",
      "[Val #9] Loss: 0.0378 Acc: 99.2754% Time: 669.7485s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10   #(set no of epochs)\n",
    "start_time = time.time() #(for showing time)\n",
    "\n",
    "for epoch in range(num_epochs): #(loop for every epoch)\n",
    "    print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()    #(training model)\n",
    "    running_loss = 0.   #(set loss 0)\n",
    "    running_corrects = 0 \n",
    "    # load a batch data of images\n",
    "    targets = []\n",
    "    results = []\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device) \n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        results.append(preds)\n",
    "        targets.append(labels)\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    results =torch.cat(results, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "\n",
    "    results = results.to('cpu').numpy().flatten()\n",
    "    targets = targets.to('cpu').numpy().flatten()\n",
    "\n",
    "    f1_value =  f1_score(results, targets)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "    print('F1-Score', f1_value)\n",
    "    \"\"\" Val Phase \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        targets = []\n",
    "        results = []\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            results.append(preds)\n",
    "            targets.append(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_corrects / len(val_dataset) * 100.\n",
    "        results = torch.cat(results, dim=0)\n",
    "        targets =torch.cat(targets, dim=0)\n",
    "        results = results.to('cpu').numpy().flatten()\n",
    "        targets = targets.to('cpu').numpy().flatten()\n",
    "        f1_value =  f1_score(results, targets)\n",
    "        print('F1-Score', f1_value)\n",
    "        print('[Val #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
