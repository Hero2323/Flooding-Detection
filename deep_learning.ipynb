{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data.dataset import Dataset \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms,models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.metrics import f1_score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), # data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "     transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "     transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"Data/train/\"\n",
    "test_dir = \"Data/test/\"\n",
    "val_dir= \"Data/val/\"\n",
    "train_flooded_dir = \"Data/train/flooded/\"\n",
    "train_non_flooded_dir = \"Data/train/non-flooded/\"\n",
    "val_flooded_dir = \"Data/val/flooded/\"\n",
    "val_non_flooded_dir = \"Data/val/non-flooded/\"\n",
    "test_flooded_dir = \"Data/test/flooded/\"\n",
    "test_non_flooded_dir = \"Data/test/non-flooded/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(train_dir, transforms_train)\n",
    "test_dataset = ImageFolder(test_dir, transforms_test)\n",
    "val_dataset = ImageFolder(val_dir, transforms_val)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=12, shuffle=True, num_workers=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 644\n",
      "Test dataset size: 140\n",
      "Val dataset size: 138\n",
      "Class names: ['flooded', 'non-flooded']\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset size:', len(train_dataset))\n",
    "print('Test dataset size:', len(test_dataset))\n",
    "print('Val dataset size:', len(val_dataset))\n",
    "class_names = train_dataset.classes\n",
    "print('Class names:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rorod\\miniforge3\\envs\\new_python_nlp_2\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\Users\\rorod\\miniforge3\\envs\\new_python_nlp_2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)   #load resnet18 model\n",
    "num_features = model.fc.in_features     #extract fc layers features\n",
    "model.fc = nn.Linear(num_features, 2) #(num_of_class == 2)\n",
    "model = model.to(device) \n",
    "criterion = nn.CrossEntropyLoss()  #(set loss function)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 running\n",
      "[Train #0] Loss: 0.4320 Acc: 78.1056% Time: 70.0046s\n",
      "F1-Score 0.7765451664025357\n",
      "[Val #0] Loss: 0.1468 Acc: 94.9275% Time: 80.0055s\n",
      "F1-Score 0.951048951048951\n",
      "Epoch 1 running\n",
      "[Train #1] Loss: 0.2395 Acc: 90.3727% Time: 148.0924s\n",
      "F1-Score 0.9040247678018576\n",
      "[Val #1] Loss: 0.1133 Acc: 97.1014% Time: 158.4764s\n",
      "F1-Score 0.9714285714285714\n",
      "Epoch 2 running\n",
      "[Train #2] Loss: 0.2164 Acc: 90.8385% Time: 223.6860s\n",
      "F1-Score 0.9079563182527302\n",
      "[Val #2] Loss: 0.1418 Acc: 94.9275% Time: 231.7967s\n",
      "F1-Score 0.951048951048951\n",
      "Epoch 3 running\n",
      "[Train #3] Loss: 0.1638 Acc: 94.5652% Time: 294.0051s\n",
      "F1-Score 0.9455676516329704\n",
      "[Val #3] Loss: 0.0790 Acc: 97.8261% Time: 301.1646s\n",
      "F1-Score 0.9784172661870504\n",
      "Epoch 4 running\n",
      "[Train #4] Loss: 0.1939 Acc: 92.0807% Time: 363.9090s\n",
      "F1-Score 0.9216589861751152\n",
      "[Val #4] Loss: 0.0660 Acc: 97.1014% Time: 371.2928s\n",
      "F1-Score 0.9710144927536232\n",
      "Epoch 5 running\n",
      "[Train #5] Loss: 0.0983 Acc: 96.1180% Time: 435.7382s\n",
      "F1-Score 0.9614791987673343\n",
      "[Val #5] Loss: 0.0774 Acc: 97.1014% Time: 443.8100s\n",
      "F1-Score 0.9714285714285714\n",
      "Epoch 6 running\n",
      "[Train #6] Loss: 0.1140 Acc: 95.4969% Time: 506.4310s\n",
      "F1-Score 0.9553158705701079\n",
      "[Val #6] Loss: 0.0500 Acc: 98.5507% Time: 514.9999s\n",
      "F1-Score 0.9855072463768116\n",
      "Epoch 7 running\n",
      "[Train #7] Loss: 0.0834 Acc: 97.5155% Time: 580.6418s\n",
      "F1-Score 0.9753086419753085\n",
      "[Val #7] Loss: 0.0334 Acc: 99.2754% Time: 588.1173s\n",
      "F1-Score 0.9927007299270074\n",
      "Epoch 8 running\n",
      "[Train #8] Loss: 0.1606 Acc: 94.2547% Time: 651.9715s\n",
      "F1-Score 0.9428129829984544\n",
      "[Val #8] Loss: 0.0474 Acc: 98.5507% Time: 659.6241s\n",
      "F1-Score 0.9857142857142858\n",
      "Epoch 9 running\n",
      "[Train #9] Loss: 0.1269 Acc: 95.4969% Time: 722.5218s\n",
      "F1-Score 0.9554531490015361\n",
      "[Val #9] Loss: 0.1012 Acc: 97.8261% Time: 730.1535s\n",
      "F1-Score 0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10   #(set no of epochs)\n",
    "start_time = time.time() #(for showing time)\n",
    "\n",
    "for epoch in range(num_epochs): #(loop for every epoch)\n",
    "    print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()    #(training model)\n",
    "    running_loss = 0.   #(set loss 0)\n",
    "    running_corrects = 0 \n",
    "    # load a batch data of images\n",
    "    targets = []\n",
    "    results = []\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device) \n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        results.append(preds)\n",
    "        targets.append(labels)\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    results =torch.cat(results, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "\n",
    "    results = results.to('cpu').numpy().flatten()\n",
    "    targets = targets.to('cpu').numpy().flatten()\n",
    "\n",
    "    f1_value =  f1_score(results, targets)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "    print('F1-Score', f1_value)\n",
    "    \"\"\" Val Phase \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        targets = []\n",
    "        results = []\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            results.append(preds)\n",
    "            targets.append(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_corrects / len(val_dataset) * 100.\n",
    "        results = torch.cat(results, dim=0)\n",
    "        targets =torch.cat(targets, dim=0)\n",
    "        results = results.to('cpu').numpy().flatten()\n",
    "        targets = targets.to('cpu').numpy().flatten()\n",
    "        f1_value =  f1_score(results, targets)\n",
    "        print('[Val #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))\n",
    "        print('F1-Score', f1_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score 0.9655172413793104\n",
      "[Val #9] Loss: 0.0841 Acc: 96.4286% Time: 777.8949s\n"
     ]
    }
   ],
   "source": [
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        targets = []\n",
    "        results = []\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            results.append(preds)\n",
    "            targets.append(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(test_dataset)\n",
    "        epoch_acc = running_corrects / len(test_dataset) * 100.\n",
    "        results = torch.cat(results, dim=0)\n",
    "        targets =torch.cat(targets, dim=0)\n",
    "        results = results.to('cpu').numpy().flatten()\n",
    "        targets = targets.to('cpu').numpy().flatten()\n",
    "        f1_value =  f1_score(results, targets)\n",
    "        print('F1-Score', f1_value)\n",
    "        print('[Val #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
