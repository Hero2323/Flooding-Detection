{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "from torch.utils.data.dataset import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms,models\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/test/flooded/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(folder_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_file = self.image_files[index]\n",
    "     \n",
    "        image_path =os.path.join(self.folder_path, image_file)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(test_dir, transforms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(test_dataset.folder_path, os.listdir(test_dataset.folder_path)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model =models.regnet_x_1_6gf()\n",
    "num_features = classification_model.fc.in_features   \n",
    "classification_model.fc = nn.Linear(num_features, 2) \n",
    "classification_model.load_state_dict(torch.load(\"classification_model.pt\"))\n",
    "classification_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "        for inputs in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "                inputs = inputs.to(device) \n",
    "                outputs = classification_model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                results.append(preds)\n",
    "        #0 flooded , 1 non flooded \n",
    "        results = torch.cat(results, dim=0)\n",
    "        results = results.to('cpu').numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preds.txt', 'w') as f:\n",
    "    # Loop over the values\n",
    "    for value in results:\n",
    "        # Check if the value is equal to 0\n",
    "        if value == 0:\n",
    "            # Write \"flooded\" to the text file\n",
    "            f.write('1\\n')\n",
    "        else:\n",
    "            # Write \"non flooded\" to the text file\n",
    "            f.write('0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:10<00:00,  6.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make another pass through the data this time check if the results[index] == 0\n",
    "# This means that the image is flooded --> Go ahead and segment it and produce a new \n",
    "# Image with the two segments colored differently\n",
    "\n",
    "ENCODER='resnet18'\n",
    "WEIGHTS='imagenet'\n",
    "\n",
    "segmentation_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_dataset.transform = segmentation_transforms\n",
    "\n",
    "output_dir = 'segmented_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "class SegmentationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModel,self).__init__()\n",
    "\n",
    "        self.arc=smp.Unet(\n",
    "            encoder_name=ENCODER,\n",
    "            encoder_weights=WEIGHTS,\n",
    "            in_channels=3,\n",
    "            classes=1,\n",
    "            activation=None\n",
    "        )\n",
    "    def forward(self,images,masks=None):\n",
    "        logits=self.arc(images)\n",
    "\n",
    "        if masks!=None:\n",
    "            loss1=DiceLoss(mode='binary')(logits,masks)\n",
    "            loss2=nn.BCEWithLogitsLoss()(logits,masks)\n",
    "            return logits,loss1,loss2\n",
    "        return logits\n",
    "    \n",
    "def apply_mask(image, mask, segment_1_color=(0, 0, 255), segment_2_color=(1, 1, 1)):\n",
    "    # Convert the image and mask to numpy arrays\n",
    "    image_np = np.array(image)\n",
    "    mask_np = np.array(mask)\n",
    "\n",
    "    # Create a new RGB image with the specified color where the mask is 1\n",
    "    color_image = np.zeros(image_np.shape, dtype=np.uint8)\n",
    "    color_image[mask_np == 1] = segment_1_color\n",
    "    color_image[mask_np != 1] = segment_2_color\n",
    "    \n",
    "    # Combine the original image with the color image\n",
    "    masked_image = Image.fromarray(color_image)\n",
    "\n",
    "    return masked_image\n",
    "    \n",
    "segmentation_model = SegmentationModel()\n",
    "segmentation_model.load_state_dict(torch.load(\"segmentation_model.pt\"))\n",
    "segmentation_model.to(device)\n",
    "\n",
    "segmentation_model.eval()\n",
    "with torch.no_grad():\n",
    "    for index, inputs in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        if results[index] == 1:\n",
    "            continue\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = segmentation_model(inputs)\n",
    "        predicted = outputs > 0.5\n",
    "        mask = predicted.squeeze().cpu().numpy()\n",
    "\n",
    "        # Convert the inputs tensor to a PIL Image\n",
    "        image = to_pil_image(inputs.squeeze().cpu())\n",
    "\n",
    "        masked_image = apply_mask(image, mask)\n",
    "        \n",
    "        original_image = Image.open(os.path.join(test_dataset.folder_path, os.listdir(test_dataset.folder_path)[index]))\n",
    "        masked_image = masked_image.resize(original_image.size)\n",
    "        \n",
    "        masked_image.save(os.path.join(output_dir, os.listdir(test_dataset.folder_path)[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eefc6a63c6d719296cee5685f23fefb92aa63e2e9fdaf52ddbdc4ce266c7bb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
