{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is made to be run once initially, to resize the dataset & create 3 new datasets\n",
    "# 1. MAX_SIZE \n",
    "# 2. MIN_SIZE\n",
    "# 3. MEAN_SIZE which is the mean of all the sizes rounded to nearest integer\n",
    "# 4. FIXED_SIZE_interpolation which is 256x256\n",
    "# 5. FIXED_SIZE_MIDDLE_CROP which is 256x256 \n",
    "#    (this interpolates if image is smaller otherwise crops the middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_PATH = 'dataset'\n",
    "FLOODED_PATH = 'flooded'\n",
    "NON_FLOODED_PATH = 'non-flooded'\n",
    "FIXED_SIZE = 224 # ! Change this if need another fixed size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'd:\\\\Fourth_Year\\\\Second_Term\\\\BD\\\\Flooding-Detection\\\\dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd()\n\u001b[0;32m      5\u001b[0m new_dataset_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m os\u001b[39m.\u001b[39;49mmkdir(new_dataset_path)\n\u001b[0;32m      7\u001b[0m new_flooded_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(new_dataset_path, FLOODED_PATH)\n\u001b[0;32m      8\u001b[0m os\u001b[39m.\u001b[39mmkdir(new_flooded_path)\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'd:\\\\Fourth_Year\\\\Second_Term\\\\BD\\\\Flooding-Detection\\\\dataset'"
     ]
    }
   ],
   "source": [
    "# Move the FLOODED_PATH and NON_FLOODED_PATH to a new normal directoy\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "new_dataset_path = os.path.join(path, 'dataset')\n",
    "os.mkdir(new_dataset_path)\n",
    "new_flooded_path = os.path.join(new_dataset_path, FLOODED_PATH)\n",
    "os.mkdir(new_flooded_path)\n",
    "new_non_flooded_path = os.path.join(new_dataset_path, NON_FLOODED_PATH)\n",
    "os.mkdir(new_non_flooded_path)\n",
    "\n",
    "for image in tqdm(os.listdir(os.path.join(path, os.path.join(DATASET_PATH, FLOODED_PATH)))):\n",
    "    shutil.move(os.path.join(path, os.path.join(DATASET_PATH, FLOODED_PATH), image), new_flooded_path)\n",
    "for image in tqdm(os.listdir(os.path.join(path, os.path.join(DATASET_PATH, NON_FLOODED_PATH)))):\n",
    "    shutil.move(os.path.join(path, os.path.join(DATASET_PATH, NON_FLOODED_PATH), image), new_non_flooded_path)\n",
    "\n",
    "# Remove the old FLOODED_PATH and NON_FLOODED_PATH\n",
    "os.rmdir(os.path.join(path, os.path.join(DATASET_PATH, FLOODED_PATH)))\n",
    "os.rmdir(os.path.join(path, os.path.join(DATASET_PATH, NON_FLOODED_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the resizig part\n",
    "# Create three new folders in the dataset folder\n",
    "# 1. max_size\n",
    "# 2. min_size\n",
    "# 3. mean_size\n",
    "# 4. fixed_size_interpolation\n",
    "# 5. fixed_size_middle_crop\n",
    "\n",
    "# Create the folders\n",
    "max_size_path = os.path.join(path, DATASET_PATH, 'max_size')\n",
    "min_size_path = os.path.join(path, DATASET_PATH, 'min_size')\n",
    "mean_size_path = os.path.join(path, DATASET_PATH, 'mean_size')\n",
    "fixed_size_interpolation_path = os.path.join(path, DATASET_PATH, 'fixed_size_interpolation')\n",
    "fixed_size_middle_crop_path = os.path.join(path, DATASET_PATH, 'fixed_size_middle_crop')\n",
    "\n",
    "os.mkdir(max_size_path)\n",
    "os.mkdir(min_size_path)\n",
    "os.mkdir(mean_size_path)\n",
    "os.mkdir(fixed_size_interpolation_path)\n",
    "os.mkdir(fixed_size_middle_crop_path)\n",
    "\n",
    "os.mkdir(os.path.join(max_size_path, FLOODED_PATH))\n",
    "os.mkdir(os.path.join(max_size_path, NON_FLOODED_PATH))\n",
    "\n",
    "os.mkdir(os.path.join(min_size_path, FLOODED_PATH))\n",
    "os.mkdir(os.path.join(min_size_path, NON_FLOODED_PATH))\n",
    "\n",
    "os.mkdir(os.path.join(mean_size_path, FLOODED_PATH))\n",
    "os.mkdir(os.path.join(mean_size_path, NON_FLOODED_PATH))\n",
    "\n",
    "os.mkdir(os.path.join(fixed_size_interpolation_path, FLOODED_PATH))\n",
    "os.mkdir(os.path.join(fixed_size_interpolation_path, NON_FLOODED_PATH))\n",
    "\n",
    "os.mkdir(os.path.join(fixed_size_middle_crop_path, FLOODED_PATH))\n",
    "os.mkdir(os.path.join(fixed_size_middle_crop_path, NON_FLOODED_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths = []\n",
    "\n",
    "folder_path = os.path.join(path, os.path.join(new_dataset_path, FLOODED_PATH))\n",
    "for image in os.listdir(folder_path):\n",
    "    image_path = os.path.join(folder_path, image)\n",
    "    images_paths.append(image_path)\n",
    "\n",
    "folder_path = os.path.join(path, os.path.join(new_dataset_path, NON_FLOODED_PATH))\n",
    "for image in os.listdir(folder_path):\n",
    "    image_path = os.path.join(folder_path, image)\n",
    "    images_paths.append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 922/922 [00:58<00:00, 15.75it/s]\n"
     ]
    }
   ],
   "source": [
    "image_sizes = []\n",
    "\n",
    "for image_path in tqdm(images_paths):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_sizes.append((image.shape[0], image.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max dimensions:  (3072, 4720)\n",
      "Min dimensions:  (152, 123)\n",
      "Mean dimensions:  (1352, 1794)\n"
     ]
    }
   ],
   "source": [
    "max_width = max(image_sizes, key=lambda x: x[0])[0]\n",
    "max_height = max(image_sizes, key=lambda x: x[1])[1]\n",
    "\n",
    "min_width = min(image_sizes, key=lambda x: x[0])[0]\n",
    "min_height = min(image_sizes, key=lambda x: x[1])[1]\n",
    "\n",
    "mean_width = int(round(sum([x[0] for x in image_sizes]) / len(image_sizes)))\n",
    "mean_height = int(round(sum([x[1] for x in image_sizes]) / len(image_sizes)))\n",
    "\n",
    "print('Max dimensions: ', (max_width, max_height))\n",
    "print('Min dimensions: ', (min_width, min_height))\n",
    "print('Mean dimensions: ', (mean_width, mean_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 922/922 [05:19<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Resize images\n",
    "\n",
    "for image_path in tqdm(images_paths):\n",
    "    # To shrink an image, it will generally look best with INTER_AREA interpolation,\n",
    "    # To enlarge an image, it will generally look best with INTER_CUBIC\n",
    "    # ! From the docs\n",
    "    image = cv2.imread(image_path)\n",
    "    max_image = cv2.resize(image, (max_width, max_height), interpolation=cv2.INTER_CUBIC)\n",
    "    min_image = cv2.resize(image, (min_width, min_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    if image.shape[0] * image.shape[1] > mean_width * mean_height:\n",
    "        mean_image = cv2.resize(image, (mean_width, mean_height), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        mean_image = cv2.resize(image, (mean_width, mean_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    if image.shape[0] * image.shape[1] > FIXED_SIZE * FIXED_SIZE:\n",
    "        fixed_size_interpolation_image = cv2.resize(image, (FIXED_SIZE, FIXED_SIZE), interpolation=cv2.INTER_AREA)\n",
    "    else: \n",
    "        fixed_size_interpolation_image = cv2.resize(image, (FIXED_SIZE, FIXED_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    if image.shape[0] > FIXED_SIZE and image.shape[1] > FIXED_SIZE:\n",
    "        fixed_size_middle_crop_image = image[image.shape[0] // 2 - FIXED_SIZE // 2: image.shape[0] // 2 + FIXED_SIZE // 2,\n",
    "                                             image.shape[1] // 2 - FIXED_SIZE // 2: image.shape[1] // 2 + FIXED_SIZE // 2]\n",
    "    else:\n",
    "        fixed_size_middle_crop_image = cv2.resize(image, (FIXED_SIZE, FIXED_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Save the images\n",
    "    if 'non-flooded' not in image_path:\n",
    "        name = image_path.split(FLOODED_PATH)[-1]\n",
    "        while name[0] == '\\\\':\n",
    "            name = name[1:]\n",
    "        cv2.imwrite(os.path.join(max_size_path, FLOODED_PATH, name), max_image)\n",
    "        cv2.imwrite(os.path.join(min_size_path, FLOODED_PATH, name), min_image)\n",
    "        cv2.imwrite(os.path.join(mean_size_path, FLOODED_PATH, name), mean_image)\n",
    "        cv2.imwrite(os.path.join(fixed_size_interpolation_path, FLOODED_PATH, name), fixed_size_interpolation_image)\n",
    "        cv2.imwrite(os.path.join(fixed_size_middle_crop_path, FLOODED_PATH, name), fixed_size_middle_crop_image)\n",
    "\n",
    "    else:\n",
    "        name = image_path.split(NON_FLOODED_PATH)[-1]\n",
    "        while name[0] == '\\\\':\n",
    "            name = name[1:]\n",
    "        cv2.imwrite(os.path.join(max_size_path, NON_FLOODED_PATH, name), max_image)\n",
    "        cv2.imwrite(os.path.join(min_size_path, NON_FLOODED_PATH, name), min_image)\n",
    "        cv2.imwrite(os.path.join(mean_size_path, NON_FLOODED_PATH, name), mean_image)\n",
    "        cv2.imwrite(os.path.join(fixed_size_interpolation_path, NON_FLOODED_PATH, name), fixed_size_interpolation_image)\n",
    "        cv2.imwrite(os.path.join(fixed_size_middle_crop_path, NON_FLOODED_PATH, name), fixed_size_middle_crop_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
