{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T13:42:49.385554Z","iopub.status.busy":"2023-05-20T13:42:49.385138Z","iopub.status.idle":"2023-05-20T13:43:12.484641Z","shell.execute_reply":"2023-05-20T13:43:12.483523Z","shell.execute_reply.started":"2023-05-20T13:42:49.385521Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install segmentation-models-pytorch > /dev/null"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T13:43:12.488357Z","iopub.status.busy":"2023-05-20T13:43:12.487957Z","iopub.status.idle":"2023-05-20T13:43:30.397783Z","shell.execute_reply":"2023-05-20T13:43:30.396822Z","shell.execute_reply.started":"2023-05-20T13:43:12.488316Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import segmentation_models_pytorch as smp\n","from segmentation_models_pytorch.losses import DiceLoss\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","import os\n","import numpy as np\n","import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T13:43:30.401038Z","iopub.status.busy":"2023-05-20T13:43:30.399006Z","iopub.status.idle":"2023-05-20T13:43:30.411185Z","shell.execute_reply":"2023-05-20T13:43:30.410349Z","shell.execute_reply.started":"2023-05-20T13:43:30.401001Z"},"trusted":true},"outputs":[],"source":["class WaterBodiesDataset(Dataset):\n","    def __init__(self, data_dir, transform=None):\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.image_list = [f for f in os.listdir(os.path.join(data_dir, 'Image')) if f.endswith('.jpg')]\n","\n","    def __len__(self):\n","        return len(self.image_list)\n","\n","    def __getitem__(self, idx):\n","        image_name = self.image_list[idx]\n","        image_path = os.path.join(self.data_dir, 'Image', image_name)\n","        mask_name = os.path.splitext(image_name)[0] + '.png'\n","        mask_path = os.path.join(self.data_dir, 'Mask', mask_name)\n","\n","        image = Image.open(image_path).convert('RGB')\n","        mask = Image.open(mask_path).convert('L')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","            mask = self.transform(mask)\n","\n","        return image, mask\n","\n","\n","data_transforms = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor()\n","])"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T13:43:30.414180Z","iopub.status.busy":"2023-05-20T13:43:30.413831Z","iopub.status.idle":"2023-05-20T13:43:30.454748Z","shell.execute_reply":"2023-05-20T13:43:30.453985Z","shell.execute_reply.started":"2023-05-20T13:43:30.414149Z"},"trusted":true},"outputs":[],"source":["data_dir = '/kaggle/input/flood-area-segmentation'\n","dataset = WaterBodiesDataset(data_dir, transform=data_transforms)\n","dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T13:43:30.456746Z","iopub.status.busy":"2023-05-20T13:43:30.456152Z","iopub.status.idle":"2023-05-20T13:43:30.460423Z","shell.execute_reply":"2023-05-20T13:43:30.459542Z","shell.execute_reply.started":"2023-05-20T13:43:30.456714Z"},"trusted":true},"outputs":[],"source":["ENCODER='resnet18'\n","WEIGHTS='imagenet'"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T13:43:30.462703Z","iopub.status.busy":"2023-05-20T13:43:30.461759Z","iopub.status.idle":"2023-05-20T13:43:30.474566Z","shell.execute_reply":"2023-05-20T13:43:30.473449Z","shell.execute_reply.started":"2023-05-20T13:43:30.462666Z"},"trusted":true},"outputs":[],"source":["class SegmentationModel(nn.Module):\n","    def __init__(self):\n","        super(SegmentationModel,self).__init__()\n","\n","        self.arc=smp.Unet(\n","            encoder_name=ENCODER,\n","            encoder_weights=WEIGHTS,\n","            in_channels=3,\n","            classes=1,\n","            activation=None\n","        )\n","    def forward(self,images,masks=None):\n","        logits=self.arc(images)\n","\n","        if masks!=None:\n","            loss1=DiceLoss(mode='binary')(logits,masks)\n","            loss2=nn.BCEWithLogitsLoss()(logits,masks)\n","            return logits,loss1,loss2\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T13:48:03.653881Z","iopub.status.busy":"2023-05-20T13:48:03.653514Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 196MB/s] \n","Epoch: 1, Loss: 0.489, Accuracy: 0.731: 100%|██████████| 73/73 [00:30<00:00,  2.43it/s]\n","Epoch: 2, Loss: 0.438, Accuracy: 0.764: 100%|██████████| 73/73 [00:17<00:00,  4.17it/s]\n","Epoch: 3, Loss: 0.426, Accuracy: 0.774: 100%|██████████| 73/73 [00:17<00:00,  4.24it/s]\n","Epoch: 4, Loss: 0.420, Accuracy: 0.774: 100%|██████████| 73/73 [00:17<00:00,  4.18it/s]\n","Epoch: 5, Loss: 0.376, Accuracy: 0.797: 100%|██████████| 73/73 [00:17<00:00,  4.14it/s]\n","Epoch: 6, Loss: 0.389, Accuracy: 0.791: 100%|██████████| 73/73 [00:17<00:00,  4.23it/s]\n","Epoch: 7, Loss: 0.368, Accuracy: 0.803: 100%|██████████| 73/73 [00:17<00:00,  4.14it/s]\n","Epoch: 8, Loss: 0.370, Accuracy: 0.802: 100%|██████████| 73/73 [00:17<00:00,  4.20it/s]\n","Epoch: 9, Loss: 0.371, Accuracy: 0.799: 100%|██████████| 73/73 [00:17<00:00,  4.14it/s]\n","Epoch: 10, Loss: 0.368, Accuracy: 0.801: 100%|██████████| 73/73 [00:17<00:00,  4.16it/s]\n","Epoch: 11, Loss: 0.367, Accuracy: 0.802: 100%|██████████| 73/73 [00:17<00:00,  4.08it/s]\n","Epoch: 12, Loss: 0.357, Accuracy: 0.806: 100%|██████████| 73/73 [00:17<00:00,  4.16it/s]\n","Epoch: 13, Loss: 0.373, Accuracy: 0.802: 100%|██████████| 73/73 [00:17<00:00,  4.08it/s]\n","Epoch: 14, Loss: 0.362, Accuracy: 0.803: 100%|██████████| 73/73 [00:17<00:00,  4.10it/s]\n","Epoch: 15, Loss: 0.348, Accuracy: 0.813: 100%|██████████| 73/73 [00:17<00:00,  4.17it/s]\n","Epoch: 16, Loss: 0.364, Accuracy: 0.802: 100%|██████████| 73/73 [00:17<00:00,  4.11it/s]\n","Epoch: 17, Loss: 0.346, Accuracy: 0.813: 100%|██████████| 73/73 [00:17<00:00,  4.15it/s]\n","Epoch: 18, Loss: 0.339, Accuracy: 0.821: 100%|██████████| 73/73 [00:17<00:00,  4.09it/s]\n","Epoch: 19, Loss: 0.328, Accuracy: 0.824: 100%|██████████| 73/73 [00:17<00:00,  4.17it/s]\n","Epoch: 20, Loss: 0.344, Accuracy: 0.818: 100%|██████████| 73/73 [00:18<00:00,  4.03it/s]\n","Epoch: 21, Loss: 0.345, Accuracy: 0.816: 100%|██████████| 73/73 [00:18<00:00,  3.87it/s]\n","Epoch: 22, Loss: 0.335, Accuracy: 0.823: 100%|██████████| 73/73 [00:18<00:00,  3.99it/s]\n","Epoch: 23, Loss: 0.323, Accuracy: 0.827: 100%|██████████| 73/73 [00:17<00:00,  4.09it/s]\n","Epoch: 24, Loss: 0.306, Accuracy: 0.833: 100%|██████████| 73/73 [00:17<00:00,  4.15it/s]\n","Epoch: 25, Loss: 0.319, Accuracy: 0.830: 100%|██████████| 73/73 [00:17<00:00,  4.10it/s]\n","Epoch: 26, Loss: 0.312, Accuracy: 0.835: 100%|██████████| 73/73 [00:17<00:00,  4.17it/s]\n","Epoch: 27, Loss: 0.309, Accuracy: 0.834: 100%|██████████| 73/73 [00:17<00:00,  4.08it/s]\n","Epoch: 28, Loss: 0.320, Accuracy: 0.827: 100%|██████████| 73/73 [00:17<00:00,  4.06it/s]\n","Epoch: 29, Loss: 0.332, Accuracy: 0.820: 100%|██████████| 73/73 [00:18<00:00,  3.87it/s]\n","Epoch: 30, Loss: 0.303, Accuracy: 0.835: 100%|██████████| 73/73 [00:18<00:00,  4.02it/s]\n","Epoch: 31, Loss: 0.298, Accuracy: 0.841: 100%|██████████| 73/73 [00:19<00:00,  3.79it/s]\n","Epoch: 32, Loss: 0.298, Accuracy: 0.839: 100%|██████████| 73/73 [00:17<00:00,  4.09it/s]\n","Epoch: 33, Loss: 0.285, Accuracy: 0.842: 100%|██████████| 73/73 [00:19<00:00,  3.75it/s]\n","Epoch: 34, Loss: 0.313, Accuracy: 0.834: 100%|██████████| 73/73 [00:17<00:00,  4.11it/s]\n","Epoch: 35, Loss: 0.291, Accuracy: 0.844: 100%|██████████| 73/73 [00:17<00:00,  4.06it/s]\n","Epoch: 36, Loss: 0.290, Accuracy: 0.843: 100%|██████████| 73/73 [00:17<00:00,  4.14it/s]\n","Epoch: 37, Loss: 0.282, Accuracy: 0.850: 100%|██████████| 73/73 [00:18<00:00,  4.05it/s]\n","Epoch: 38, Loss: 0.275, Accuracy: 0.850: 100%|██████████| 73/73 [00:17<00:00,  4.15it/s]\n","Epoch: 39, Loss: 0.289, Accuracy: 0.843: 100%|██████████| 73/73 [00:17<00:00,  4.12it/s]\n","Epoch: 40, Loss: 0.271, Accuracy: 0.850: 100%|██████████| 73/73 [00:17<00:00,  4.15it/s]\n","Epoch: 41, Loss: 0.288, Accuracy: 0.843: 100%|██████████| 73/73 [00:18<00:00,  4.05it/s]\n","Epoch: 42, Loss: 0.291, Accuracy: 0.842: 100%|██████████| 73/73 [00:17<00:00,  4.13it/s]\n","Epoch: 43, Loss: 0.274, Accuracy: 0.851: 100%|██████████| 73/73 [00:17<00:00,  4.15it/s]\n","Epoch: 44, Loss: 0.293, Accuracy: 0.844: 100%|██████████| 73/73 [00:17<00:00,  4.07it/s]\n","Epoch: 45, Loss: 0.276, Accuracy: 0.851: 100%|██████████| 73/73 [00:17<00:00,  4.16it/s]\n","Epoch: 46, Loss: 0.275, Accuracy: 0.852: 100%|██████████| 73/73 [00:17<00:00,  4.09it/s]\n","Epoch: 47, Loss: 0.263, Accuracy: 0.855: 100%|██████████| 73/73 [00:17<00:00,  4.17it/s]\n","Epoch: 48, Loss: 0.270, Accuracy: 0.853: 100%|██████████| 73/73 [00:17<00:00,  4.08it/s]\n","Epoch: 49, Loss: 0.264, Accuracy: 0.853: 100%|██████████| 73/73 [00:17<00:00,  4.15it/s]\n","Epoch: 50, Loss: 0.274, Accuracy: 0.850: 100%|██████████| 73/73 [00:17<00:00,  4.06it/s]\n","Epoch: 51, Loss: 0.269, Accuracy: 0.852: 100%|██████████| 73/73 [00:17<00:00,  4.09it/s]\n","Epoch: 52, Loss: 0.273, Accuracy: 0.849: 100%|██████████| 73/73 [00:17<00:00,  4.16it/s]\n","Epoch: 53, Loss: 0.281, Accuracy: 0.845: 100%|██████████| 73/73 [00:17<00:00,  4.08it/s]\n","Epoch: 54, Loss: 0.269, Accuracy: 0.852: 100%|██████████| 73/73 [00:17<00:00,  4.12it/s]\n","Epoch: 55, Loss: 0.270, Accuracy: 0.852: 100%|██████████| 73/73 [00:17<00:00,  4.11it/s]\n","Epoch: 56, Loss: 0.262, Accuracy: 0.855: 100%|██████████| 73/73 [00:17<00:00,  4.12it/s]\n","Epoch: 57, Loss: 0.249, Accuracy: 0.859: 100%|██████████| 73/73 [00:17<00:00,  4.13it/s]\n","Epoch: 58, Loss: 0.278, Accuracy: 0.847: 100%|██████████| 73/73 [00:17<00:00,  4.09it/s]\n","Epoch: 59, Loss: 0.259, Accuracy: 0.857: 100%|██████████| 73/73 [00:17<00:00,  4.15it/s]\n","Epoch: 60, Loss: 0.261, Accuracy: 0.858: 100%|██████████| 73/73 [00:17<00:00,  4.11it/s]\n","Epoch: 61, Loss: 0.267, Accuracy: 0.852: 100%|██████████| 73/73 [00:17<00:00,  4.15it/s]\n","Epoch: 62, Loss: 0.258, Accuracy: 0.858: 100%|██████████| 73/73 [00:17<00:00,  4.10it/s]\n","Epoch: 63, Loss: 0.265, Accuracy: 0.855: 100%|██████████| 73/73 [00:17<00:00,  4.16it/s]\n","Epoch: 64, Loss: 0.252, Accuracy: 0.861: 100%|██████████| 73/73 [00:17<00:00,  4.08it/s]\n","Epoch: 65, Loss: 0.235, Accuracy: 0.870:  71%|███████   | 52/73 [00:13<00:05,  3.59it/s]"]}],"source":["# check if CUDA is available\n","use_cuda = torch.cuda.is_available()\n","\n","# set the device to use for computations\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","# define the model\n","model = SegmentationModel()\n","model.to(device)\n","\n","# define the loss function\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","# define the number of epochs to train for\n","num_epochs = 500\n","\n","# create a SummaryWriter to log training progress to TensorBoard\n","writer = SummaryWriter()\n","\n","highest_accuracy = 0\n","model_path = 'resnet_18_final.pt'\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    # create a progress bar using tqdm\n","    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for i, data in pbar:\n","        # get the inputs and labels and move them to the GPU\n","        inputs, labels = data\n","\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # compute the accuracy\n","        predicted = outputs > 0.5\n","        total += labels.numel()\n","        correct += (predicted == labels).sum().item()\n","\n","        # backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        # update the progress bar and print statistics\n","        running_loss += loss.item()\n","        pbar.set_description(f'Epoch: {epoch + 1}, Loss: {running_loss / (i + 1):.3f}, Accuracy: {correct / total:.3f}')\n","\n","    # log the loss and accuracy to TensorBoard\n","    writer.add_scalar('Loss/train', running_loss / len(dataloader), epoch)\n","    writer.add_scalar('Accuracy/train', correct / total, epoch)\n","    \n","    if correct / total > highest_accuracy:\n","        highest_accuracy = correct / total\n","        torch.save(model.state_dict(), model_path)\n","\n","print('Finished Training')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:06:21.510810Z","iopub.status.busy":"2023-05-20T09:06:21.510435Z","iopub.status.idle":"2023-05-20T09:06:41.242127Z","shell.execute_reply":"2023-05-20T09:06:41.240916Z","shell.execute_reply.started":"2023-05-20T09:06:21.510777Z"},"trusted":true},"outputs":[],"source":["!pip install gdown  \n","!gdown --id 16sRHSusyhK3SqUggW6ZTvEYVIUHYAl7J"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:07:09.256845Z","iopub.status.busy":"2023-05-20T09:07:09.256176Z","iopub.status.idle":"2023-05-20T09:07:17.397708Z","shell.execute_reply":"2023-05-20T09:07:17.396589Z","shell.execute_reply.started":"2023-05-20T09:07:09.256806Z"},"trusted":true},"outputs":[],"source":["from zipfile import ZipFile\n","with ZipFile('dataset.zip', 'r') as zipObj:\n","   zipObj.extractall()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:59:24.177445Z","iopub.status.busy":"2023-05-20T09:59:24.177063Z","iopub.status.idle":"2023-05-20T09:59:24.184592Z","shell.execute_reply":"2023-05-20T09:59:24.183634Z","shell.execute_reply.started":"2023-05-20T09:59:24.177413Z"},"trusted":true},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, data_dir, transform=None):\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.image_list = [f for f in os.listdir(data_dir) if f.endswith('.jpg')]\n","\n","    def __len__(self):\n","        return len(self.image_list)\n","\n","    def __getitem__(self, idx):\n","        image_name = self.image_list[idx]\n","        image_path = os.path.join(self.data_dir, image_name)\n","\n","        image = Image.open(image_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image_name, image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:59:24.782845Z","iopub.status.busy":"2023-05-20T09:59:24.782149Z","iopub.status.idle":"2023-05-20T09:59:24.788997Z","shell.execute_reply":"2023-05-20T09:59:24.787825Z","shell.execute_reply.started":"2023-05-20T09:59:24.782807Z"},"trusted":true},"outputs":[],"source":["# Test dataset path: /kaggle/working/dataset/flooded\n","test_data_dir = '/kaggle/working/dataset/flooded'\n","test_dataset = TestDataset(test_data_dir, transform=data_transforms)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:59:25.697472Z","iopub.status.busy":"2023-05-20T09:59:25.697067Z","iopub.status.idle":"2023-05-20T09:59:41.220174Z","shell.execute_reply":"2023-05-20T09:59:41.219100Z","shell.execute_reply.started":"2023-05-20T09:59:25.697439Z"},"trusted":true},"outputs":[],"source":["# create the output directory if it doesn't exist\n","os.makedirs('output', exist_ok=True)\n","\n","# set the model to evaluation mode\n","model.eval()\n","\n","with torch.no_grad():\n","    for i, data in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n","        # get the image name and input\n","        image_name, inputs = data\n","        inputs = inputs.to(device)\n","\n","        # forward pass\n","        outputs = model(inputs)\n","        predicted = outputs > 0.5\n","\n","        # save the predicted mask\n","        mask_name = os.path.join('output', image_name[0])\n","        Image.fromarray(predicted.squeeze().cpu().numpy()).save(mask_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:59:43.064869Z","iopub.status.busy":"2023-05-20T09:59:43.064513Z","iopub.status.idle":"2023-05-20T09:59:56.253076Z","shell.execute_reply":"2023-05-20T09:59:56.252058Z","shell.execute_reply.started":"2023-05-20T09:59:43.064839Z"},"trusted":true},"outputs":[],"source":["def apply_mask(image, mask):\n","    # convert the image and mask to numpy arrays\n","    image = np.array(image)\n","    mask = np.array(mask)\n","\n","    # apply the mask to each channel of the image\n","\n","    masked_image = image.copy()\n","    masked_image[0, :, :] = image[0, :, :].copy() * mask\n","    masked_image[1, :, :] = image[1, :, :].copy() * mask\n","    masked_image[2, :, :] = image[2, :, :].copy() * mask\n","\n","    # transpose the masked image to have shape (height, width, channels)\n","    masked_image = np.transpose(masked_image, (1, 2, 0))\n","\n","    # convert the masked image to uint8\n","    masked_image = masked_image.astype(np.uint8)\n","\n","    return masked_image\n","\n","# create the mask_output directory if it doesn't exist\n","os.makedirs('mask_output', exist_ok=True)\n","\n","# create a new FloodTestDataset for the test data\n","test_data_dir = 'dataset/flooded'\n","test_dataset = TestDataset(test_data_dir, transform=data_transforms)\n","\n","# iterate over the test data\n","for i in tqdm(range(len(test_dataset)), total=len(test_dataset)):\n","    # get the image name and image\n","    image_name, image = test_dataset[i]\n","\n","    # load the predicted mask\n","    mask_name = os.path.join('output', image_name)\n","    mask = Image.open(mask_name).convert('L')\n","\n","    # apply the mask to the image\n","    masked_image = apply_mask(image, mask)\n","\n","    # save the masked image\n","    masked_image_name = os.path.join('mask_output', image_name)\n","    Image.fromarray(masked_image).save(masked_image_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T10:00:21.212317Z","iopub.status.busy":"2023-05-20T10:00:21.211916Z","iopub.status.idle":"2023-05-20T10:00:23.390010Z","shell.execute_reply":"2023-05-20T10:00:23.389209Z","shell.execute_reply.started":"2023-05-20T10:00:21.212275Z"},"trusted":true},"outputs":[],"source":["# Show the original image & the masked image (from mask_output folder)\n","\n","img_name = '1.jpg'\n","img_path = os.path.join('dataset/flooded/', img_name)\n","masked_img_path = os.path.join('mask_output/', img_name)\n","\n","img = Image.open(img_path)\n","masked_img = Image.open(masked_img_path)\n","\n","fig, ax = plt.subplots(1, 2, figsize=(10, 15))\n","ax[0].imshow(img)\n","ax[1].imshow(masked_img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T10:00:42.336583Z","iopub.status.busy":"2023-05-20T10:00:42.335898Z","iopub.status.idle":"2023-05-20T10:00:42.434213Z","shell.execute_reply":"2023-05-20T10:00:42.433242Z","shell.execute_reply.started":"2023-05-20T10:00:42.336542Z"},"trusted":true},"outputs":[],"source":["# Pickle the model\n","model_path = 'resnet18 - 93%.pt'\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T09:43:55.598993Z","iopub.status.busy":"2023-05-20T09:43:55.598622Z","iopub.status.idle":"2023-05-20T09:43:55.669616Z","shell.execute_reply":"2023-05-20T09:43:55.668631Z","shell.execute_reply.started":"2023-05-20T09:43:55.598961Z"},"trusted":true},"outputs":[],"source":["model.load_state_dict(torch.load(model_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-20T10:07:58.286490Z","iopub.status.busy":"2023-05-20T10:07:58.286090Z","iopub.status.idle":"2023-05-20T10:07:58.658471Z","shell.execute_reply":"2023-05-20T10:07:58.657285Z","shell.execute_reply.started":"2023-05-20T10:07:58.286457Z"},"trusted":true},"outputs":[],"source":["model.to(device)\n","\n","# define the loss function\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# define the number of epochs to train for\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    # create a progress bar using tqdm\n","    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n","    for i, data in pbar:\n","        # get the inputs and labels and move them to the GPU\n","        inputs, labels = data\n","\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # compute the accuracy\n","        predicted = outputs > 0.5\n","        total += labels.numel()\n","        correct += (predicted == labels).sum().item()\n","\n","        # backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        # update the progress bar and print statistics\n","        running_loss += loss.item()\n","        pbar.set_description(f'Epoch: {epoch + 1}, Loss: {running_loss / (i + 1):.3f}, Accuracy: {correct / total:.3f}')\n","\n","    # log the loss and accuracy to TensorBoard\n","    writer.add_scalar('Loss/train', running_loss / len(dataloader), epoch)\n","    writer.add_scalar('Accuracy/train', correct / total, epoch)\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
